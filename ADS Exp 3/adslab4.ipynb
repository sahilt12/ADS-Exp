{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('HR-Employee-Attrition.csv')\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop('DailyRate', axis=1)\n",
        "y = data['DailyRate']\n",
        "\n",
        "# Convert categorical variables to numerical using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "X_encoded = X.copy()\n",
        "for col in X_encoded.columns:\n",
        "    if X_encoded[col].dtype == 'object':\n",
        "        X_encoded[col] = label_encoder.fit_transform(X_encoded[col])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize models (excluding SVR)\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "}\n",
        "\n",
        "# Train, evaluate models, and predict house prices\n",
        "prediction_results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    prediction_results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"Predictions\": y_pred}\n",
        "\n",
        "    print(f\"Metrics for {name}:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "    print(f\"R-squared (R2): {r2}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Find the best performing model based on the R-squared score\n",
        "best_model = max(prediction_results, key=lambda x: prediction_results[x]['R2'])\n",
        "print(f\"Best performing model based on R-squared score: {best_model}\")\n",
        "\n",
        "# Predict house prices using the best model\n",
        "print(f\"\\nPredictions using the best model ({best_model}):\")\n",
        "print(prediction_results[best_model][\"Predictions\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESAWH-AtWRAx",
        "outputId": "4051bace-0a92-4f92-dedd-27622671d39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Decision Tree:\n",
            "Mean Absolute Error (MAE): 462.8537414965986\n",
            "Root Mean Squared Error (RMSE): 568.2768589652179\n",
            "R-squared (R2): -1.077351773166725\n",
            "==================================================\n",
            "Metrics for Random Forest:\n",
            "Mean Absolute Error (MAE): 347.1185714285715\n",
            "Root Mean Squared Error (RMSE): 405.33035444942345\n",
            "R-squared (R2): -0.05683785112861606\n",
            "==================================================\n",
            "Metrics for Linear Regression:\n",
            "Mean Absolute Error (MAE): 343.4192649583252\n",
            "Root Mean Squared Error (RMSE): 396.993085642734\n",
            "R-squared (R2): -0.013808639723214\n",
            "==================================================\n",
            "Best performing model based on R-squared score: Linear Regression\n",
            "\n",
            "Predictions using the best model (Linear Regression):\n",
            "[779.56457208 833.4546282  677.12761036 860.50677385 788.20230684\n",
            " 891.00695243 703.40334583 885.49548697 738.13314043 882.38547954\n",
            " 754.31090083 574.61850169 831.23663788 804.78947537 655.24394162\n",
            " 744.2110661  788.34993973 600.1464748  744.33884006 842.66735409\n",
            " 720.72158363 896.4621577  815.37769343 828.37751279 792.12290391\n",
            " 687.12546452 755.35423297 835.88890795 683.4297613  724.93349959\n",
            " 769.16501215 834.28845425 869.8798617  850.45190157 748.89658165\n",
            " 833.7188536  837.91421238 825.91408716 839.36464946 774.0410263\n",
            " 732.59884149 699.86534918 815.68666758 781.67867333 728.96461606\n",
            " 794.74737456 689.65092451 740.44047112 864.73829821 741.20050239\n",
            " 925.59663009 856.45840279 723.02403095 698.12132918 812.60220853\n",
            " 767.7271143  859.52655204 788.84334343 832.64171994 785.52429711\n",
            " 688.50308668 703.23963243 648.84136493 916.3692421  892.10015796\n",
            " 769.20078587 806.72994718 777.20435343 807.17410132 723.69525567\n",
            " 802.98494218 892.92614423 888.22247888 700.52479249 826.01473805\n",
            " 906.21961302 735.81890563 813.60995821 863.66187809 795.02966329\n",
            " 935.04850286 823.78529775 922.59944955 798.9272363  771.45568106\n",
            " 750.21281725 804.74277261 665.65060604 886.52798867 868.12456582\n",
            " 770.28182313 818.18941797 579.64714176 881.69755888 781.28594831\n",
            " 797.88128665 792.01429989 750.48402738 875.02113525 888.77879827\n",
            " 721.6932663  891.77037455 704.1139914  875.69549806 760.76740495\n",
            " 788.6351955  779.79550482 716.36362916 750.75763185 806.47748021\n",
            " 844.25681475 669.98586332 881.12146445 848.1327472  842.24153088\n",
            " 840.02555549 846.95283718 770.78085026 757.89487686 820.59327004\n",
            " 720.69097156 864.73198461 732.51143318 873.18873579 700.42833602\n",
            " 758.36172573 718.73409874 773.85922174 713.08139663 906.11560365\n",
            " 770.43431473 821.12596936 741.37149558 693.28332369 840.4967166\n",
            " 761.78319575 782.10373831 807.22839035 911.38088658 872.01161209\n",
            " 781.78534197 842.33597876 765.58257957 777.44635855 853.57637406\n",
            " 753.27843289 782.01998728 778.50674602 756.40787729 732.73288962\n",
            " 795.58207345 766.37869854 856.83514483 805.11845012 701.10863685\n",
            " 833.40428043 834.12896036 936.74893926 899.35295266 808.83554916\n",
            " 712.16929494 727.0349346  691.31864833 885.75158417 728.97641737\n",
            " 897.80268208 774.648227   797.65178974 670.17937597 770.1540726\n",
            " 806.388817   644.47022626 762.68163467 815.81728704 857.72151299\n",
            " 849.19040504 787.64638813 989.81150296 771.68602966 811.84385007\n",
            " 698.66534715 760.45627199 863.85047135 729.67915543 822.89457125\n",
            " 833.21196555 820.78684423 935.03476708 784.13296712 763.10375402\n",
            " 865.58655243 802.29182002 756.92482136 775.92620461 784.46242633\n",
            " 709.12942082 872.72187553 763.30627191 805.45505298 845.43699736\n",
            " 769.51991172 833.54000443 755.5584836  678.97785088 863.82060335\n",
            " 859.42116415 813.16948037 785.40238897 774.39236297 763.89233847\n",
            " 778.10430211 840.33178695 901.69688718 780.76780467 732.27481442\n",
            " 819.08213675 820.05400857 877.09039627 743.72643831 817.68609068\n",
            " 823.70988161 805.39168155 929.91885481 836.62411228 630.93622071\n",
            " 714.15125641 811.52249113 697.51660317 819.51762933 785.5950868\n",
            " 808.93951714 862.99792396 885.72513068 758.35558706 808.00136158\n",
            " 845.40016056 796.45498046 821.10626264 779.56789536 875.75231867\n",
            " 747.46572492 704.83796514 813.77578121 764.16476602 780.12560589\n",
            " 754.26433811 735.72607247 775.38441538 902.84731127 792.06729414\n",
            " 820.46158151 717.87781337 632.90621401 912.2628096  822.40602437\n",
            " 844.31695317 785.40604519 762.99912333 819.89420826 735.45027257\n",
            " 843.25157646 755.12233936 866.60316371 801.32177733 787.03803292\n",
            " 839.57793685 979.53370138 795.8133274  810.83739352 831.80115551\n",
            " 743.94511388 838.00789329 885.15847621 768.86036419 789.77291389\n",
            " 687.2939114  646.29982496 772.19026137 777.37483759 657.27250566\n",
            " 767.32231131 898.98111276 732.56729887 849.00178576 933.59198074\n",
            " 691.28741185 703.74590252 805.45877886 850.44512855 833.05271172\n",
            " 776.05536357 787.5077477  784.97218457 769.45077268]\n"
          ]
        }
      ]
    }
  ]
}